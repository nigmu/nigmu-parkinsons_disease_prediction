{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "870d7342-26d3-41ef-a1ed-c30f0123372e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded 79613 samples from ['/home/nigmu/NPersonal/Projects/SDP/nigmu-parkinsons_disease_prediction/Dataset/Italian RGB 3/train']\n",
      "âœ… Loaded 16792 samples from ['/home/nigmu/NPersonal/Projects/SDP/nigmu-parkinsons_disease_prediction/Dataset/Italian RGB 3/val']\n",
      "âœ… Loaded 16861 samples from ['/home/nigmu/NPersonal/Projects/SDP/nigmu-parkinsons_disease_prediction/Dataset/Italian RGB 3/test']\n",
      "âœ… DataLoaders ready! Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Configuration\n",
    "DATA_ROOTS = [\n",
    "    # r\"/home/nigmu/NPersonal/Projects/SDP/nigmu-parkinsons_disease_prediction/Dataset/MDVR RGB\",\n",
    "    r\"/home/nigmu/NPersonal/Projects/SDP/nigmu-parkinsons_disease_prediction/Dataset/Italian RGB 3\"\n",
    "]\n",
    "\n",
    "# 50epochs variant ran with hop length 30 variant\n",
    "\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "NUM_WORKERS = 4  # Optimize based on CPU\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Custom Dataset Class\n",
    "class ParkinsonSpectrogramDataset(Dataset):\n",
    "    def __init__(self, root_dirs, transform=None):\n",
    "        if isinstance(root_dirs, str):  # If a single path is given, convert it to a list\n",
    "            root_dirs = [root_dirs]\n",
    "        self.root_dirs = root_dirs\n",
    "        self.transform = transform\n",
    "        self.samples = self._load_samples()\n",
    "        \n",
    "    def _load_samples(self):\n",
    "        samples = []\n",
    "        for root_dir in self.root_dirs:\n",
    "            for class_name in ['HC', 'PD']:\n",
    "                class_dir = os.path.join(root_dir, class_name)\n",
    "                if not os.path.exists(class_dir):\n",
    "                    continue\n",
    "\n",
    "                # Traverse subfolders inside HC/PD\n",
    "                for patient_folder in os.listdir(class_dir):\n",
    "                    patient_path = os.path.join(class_dir, patient_folder)\n",
    "                    if os.path.isdir(patient_path):  # Ensure it's a directory\n",
    "                        for img_file in os.listdir(patient_path):\n",
    "                            if img_file.lower().endswith('.png'):  # Only PNG images\n",
    "                                img_path = os.path.join(patient_path, img_file)\n",
    "                                samples.append((img_path, 0 if class_name == 'HC' else 1))\n",
    "\n",
    "        print(f\"âœ… Loaded {len(samples)} samples from {self.root_dirs}\")\n",
    "        return samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        img = Image.open(img_path).convert('RGB')  # Convert to RGB\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "        \n",
    "\n",
    "# ============================\n",
    "# âœ… Data Transforms\n",
    "# ============================\n",
    "\n",
    "# For training: add augmentations\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomApply([\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2)\n",
    "    ], p=0.5),  # Color jitter 50% of the time\n",
    "    transforms.RandomRotation(degrees=5),  # Small rotations\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # Small translations\n",
    "    transforms.RandomResizedCrop(size=(224, 224), scale=(0.9, 1.0), ratio=(0.9, 1.1)),  # Random crops\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # Keep it ImageNet because pretrained DenseNet expects it\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# For validation and testing: no augmentation, just resize and normalize\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize without crop\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # Same normalization for consistency\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "\n",
    "# Create Datasets (Loading from both MDVR & Italian datasets)\n",
    "train_dataset = ParkinsonSpectrogramDataset([os.path.join(root, 'train') for root in DATA_ROOTS], transform=train_transform)\n",
    "val_dataset = ParkinsonSpectrogramDataset([os.path.join(root, 'val') for root in DATA_ROOTS], transform=test_transform)\n",
    "test_dataset = ParkinsonSpectrogramDataset([os.path.join(root, 'test') for root in DATA_ROOTS], transform=test_transform)\n",
    "\n",
    "# Optimized DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, \n",
    "                          num_workers=NUM_WORKERS, pin_memory=True, persistent_workers=False)\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, \n",
    "                        num_workers=NUM_WORKERS, pin_memory=True, persistent_workers=False)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, \n",
    "                         num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "print(f\"âœ… DataLoaders ready! Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913c81c7-e3de-4760-94e9-1c9df210654f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15c2933-ce5b-4931-b935-943c56b9787d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4620849d-0a94-4175-8198-ca0bdbdcf6d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c18d334-8518-4769-97b0-9d4d8ca181ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸŒŸ Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Train Loss: 0.1355, Acc: 0.9453 | Val Loss: 0.0461, Acc: 0.9833\n",
      "\n",
      "ðŸŒŸ Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Train Loss: 0.0588, Acc: 0.9791 | Val Loss: 0.0528, Acc: 0.9809\n",
      "\n",
      "ðŸŒŸ Epoch 3/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Train Loss: 0.0440, Acc: 0.9837 | Val Loss: 0.0412, Acc: 0.9854\n",
      "\n",
      "ðŸŒŸ Epoch 4/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Train Loss: 0.0360, Acc: 0.9873 | Val Loss: 0.0353, Acc: 0.9868\n",
      "\n",
      "ðŸŒŸ Epoch 5/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Train Loss: 0.0302, Acc: 0.9889 | Val Loss: 0.0463, Acc: 0.9841\n",
      "\n",
      "ðŸŒŸ Epoch 6/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Train Loss: 0.0269, Acc: 0.9904 | Val Loss: 0.0802, Acc: 0.9730\n",
      "\n",
      "ðŸŒŸ Epoch 7/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Train Loss: 0.0243, Acc: 0.9908 | Val Loss: 0.0351, Acc: 0.9866\n",
      "\n",
      "ðŸŒŸ Epoch 8/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Train Loss: 0.0219, Acc: 0.9921 | Val Loss: 0.0256, Acc: 0.9914\n",
      "\n",
      "ðŸŒŸ Epoch 9/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Train Loss: 0.0211, Acc: 0.9923 | Val Loss: 0.0441, Acc: 0.9862\n",
      "\n",
      "ðŸŒŸ Epoch 10/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Train Loss: 0.0189, Acc: 0.9933 | Val Loss: 0.0301, Acc: 0.9905\n",
      "\n",
      "ðŸŒŸ Epoch 11/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Train Loss: 0.0173, Acc: 0.9937 | Val Loss: 0.0400, Acc: 0.9870\n",
      "\n",
      "ðŸŒŸ Epoch 12/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Train Loss: 0.0171, Acc: 0.9944 | Val Loss: 0.0522, Acc: 0.9833\n",
      "\n",
      "ðŸŒŸ Epoch 13/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Train Loss: 0.0159, Acc: 0.9943 | Val Loss: 0.0176, Acc: 0.9935\n",
      "\n",
      "ðŸŒŸ Epoch 14/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Train Loss: 0.0142, Acc: 0.9948 | Val Loss: 0.0361, Acc: 0.9890\n",
      "\n",
      "ðŸŒŸ Epoch 15/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Train Loss: 0.0141, Acc: 0.9951 | Val Loss: 0.0304, Acc: 0.9909\n",
      "\n",
      "ðŸŒŸ Epoch 16/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Train Loss: 0.0134, Acc: 0.9955 | Val Loss: 0.0261, Acc: 0.9911\n",
      "\n",
      "ðŸŒŸ Epoch 17/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Train Loss: 0.0129, Acc: 0.9953 | Val Loss: 0.0384, Acc: 0.9887\n",
      "\n",
      "ðŸŒŸ Epoch 18/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Train Loss: 0.0115, Acc: 0.9959 | Val Loss: 0.0437, Acc: 0.9856\n",
      "\n",
      "ðŸŒŸ Epoch 19/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Train Loss: 0.0119, Acc: 0.9955 | Val Loss: 0.0386, Acc: 0.9860\n",
      "\n",
      "ðŸŒŸ Epoch 20/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Train Loss: 0.0110, Acc: 0.9958 | Val Loss: 0.0229, Acc: 0.9920\n",
      "\n",
      "ðŸŒŸ Epoch 21/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Train Loss: 0.0107, Acc: 0.9962 | Val Loss: 0.0417, Acc: 0.9873\n",
      "\n",
      "ðŸŒŸ Epoch 22/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Train Loss: 0.0107, Acc: 0.9961 | Val Loss: 0.0277, Acc: 0.9912\n",
      "\n",
      "ðŸŒŸ Epoch 23/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Train Loss: 0.0098, Acc: 0.9963 | Val Loss: 0.0428, Acc: 0.9873\n",
      "\n",
      "ðŸŒŸ Epoch 24/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Train Loss: 0.0104, Acc: 0.9963 | Val Loss: 0.0393, Acc: 0.9876\n",
      "\n",
      "ðŸŒŸ Epoch 25/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Train Loss: 0.0095, Acc: 0.9967 | Val Loss: 0.0322, Acc: 0.9902\n",
      "\n",
      "ðŸŒŸ Epoch 26/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Train Loss: 0.0093, Acc: 0.9969 | Val Loss: 0.0378, Acc: 0.9892\n",
      "\n",
      "ðŸŒŸ Epoch 27/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Train Loss: 0.0096, Acc: 0.9967 | Val Loss: 0.0245, Acc: 0.9915\n",
      "\n",
      "ðŸŒŸ Epoch 28/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Train Loss: 0.0093, Acc: 0.9968 | Val Loss: 0.0407, Acc: 0.9895\n",
      "\n",
      "ðŸŒŸ Epoch 29/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Train Loss: 0.0086, Acc: 0.9971 | Val Loss: 0.0361, Acc: 0.9895\n",
      "\n",
      "ðŸŒŸ Epoch 30/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Train Loss: 0.0081, Acc: 0.9973 | Val Loss: 0.0328, Acc: 0.9890\n",
      "\n",
      "ðŸŒŸ Epoch 31/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Train Loss: 0.0080, Acc: 0.9973 | Val Loss: 0.0319, Acc: 0.9898\n",
      "\n",
      "ðŸŒŸ Epoch 32/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Train Loss: 0.0076, Acc: 0.9973 | Val Loss: 0.0245, Acc: 0.9920\n",
      "\n",
      "ðŸŒŸ Epoch 33/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Train Loss: 0.0078, Acc: 0.9971 | Val Loss: 0.0264, Acc: 0.9928\n",
      "\n",
      "ðŸŒŸ Epoch 34/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Train Loss: 0.0069, Acc: 0.9975 | Val Loss: 0.0217, Acc: 0.9930\n",
      "\n",
      "ðŸŒŸ Epoch 35/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Train Loss: 0.0075, Acc: 0.9973 | Val Loss: 0.0362, Acc: 0.9889\n",
      "\n",
      "ðŸŒŸ Epoch 36/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Train Loss: 0.0070, Acc: 0.9976 | Val Loss: 0.0429, Acc: 0.9883\n",
      "\n",
      "ðŸŒŸ Epoch 37/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Train Loss: 0.0078, Acc: 0.9972 | Val Loss: 0.0398, Acc: 0.9876\n",
      "\n",
      "ðŸŒŸ Epoch 38/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Train Loss: 0.0070, Acc: 0.9975 | Val Loss: 0.0215, Acc: 0.9927\n",
      "\n",
      "ðŸŒŸ Epoch 39/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Train Loss: 0.0060, Acc: 0.9980 | Val Loss: 0.0700, Acc: 0.9863\n",
      "\n",
      "ðŸŒŸ Epoch 40/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Train Loss: 0.0063, Acc: 0.9977 | Val Loss: 0.0449, Acc: 0.9880\n",
      "\n",
      "ðŸŒŸ Epoch 41/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Train Loss: 0.0066, Acc: 0.9977 | Val Loss: 0.0395, Acc: 0.9884\n",
      "\n",
      "ðŸŒŸ Epoch 42/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Train Loss: 0.0066, Acc: 0.9979 | Val Loss: 0.0397, Acc: 0.9852\n",
      "\n",
      "ðŸŒŸ Epoch 43/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Train Loss: 0.0061, Acc: 0.9978 | Val Loss: 0.0556, Acc: 0.9844\n",
      "\n",
      "ðŸŒŸ Epoch 44/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Train Loss: 0.0061, Acc: 0.9979 | Val Loss: 0.0446, Acc: 0.9872\n",
      "\n",
      "ðŸŒŸ Epoch 45/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Train Loss: 0.0053, Acc: 0.9981 | Val Loss: 0.0508, Acc: 0.9859\n",
      "\n",
      "ðŸŒŸ Epoch 46/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Train Loss: 0.0058, Acc: 0.9980 | Val Loss: 0.0417, Acc: 0.9886\n",
      "\n",
      "ðŸŒŸ Epoch 47/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Train Loss: 0.0058, Acc: 0.9979 | Val Loss: 0.0387, Acc: 0.9905\n",
      "\n",
      "ðŸŒŸ Epoch 48/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Train Loss: 0.0060, Acc: 0.9979 | Val Loss: 0.0936, Acc: 0.9795\n",
      "\n",
      "ðŸŒŸ Epoch 49/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Train Loss: 0.0060, Acc: 0.9980 | Val Loss: 0.0469, Acc: 0.9871\n",
      "\n",
      "ðŸŒŸ Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Train Loss: 0.0061, Acc: 0.9979 | Val Loss: 0.0403, Acc: 0.9889\n",
      "\n",
      "ðŸš€ Testing best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1054/1054 [01:14<00:00, 14.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Test Accuracy: 99.22%\n",
      "Total runtime: 20.1089 hours\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ðŸš€ Full Pipeline for Pretrained EfficientNetV2 with RGB Spectrograms\n",
    "\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models, transforms, datasets\n",
    "from tqdm import tqdm\n",
    "\n",
    "total_time_start = time.time()\n",
    "\n",
    "\n",
    "# ============================\n",
    "# âœ… Configuration\n",
    "# ============================\n",
    "# DATA_DIR = \"/home/nigmu/NPersonal/Projects/SDP/nigmu-parkinsons_disease_prediction/Dataset/MDVR RGB\"\n",
    "# DATA_DIR = \"/home/nigmu/NPersonal/Projects/SDP/nigmu-parkinsons_disease_prediction/Dataset/Italian RGB\"\n",
    "# BATCH_SIZE = 32\n",
    "NUM_CLASSES = 2\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 1e-4\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ============================\n",
    "# âœ… Data Transforms\n",
    "# ============================\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.Resize((224, 224)),  # Resize from (496x200) to 224x224 for DenseNet\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "#                          std=[0.229, 0.224, 0.225]),\n",
    "# ])\n",
    "\n",
    "# ============================\n",
    "# âœ… Dataset and DataLoader\n",
    "# ============================\n",
    "# train_dataset = datasets.ImageFolder(os.path.join(DATA_DIR, 'train'), transform=transform)\n",
    "# val_dataset   = datasets.ImageFolder(os.path.join(DATA_DIR, 'val'), transform=transform)\n",
    "# test_dataset  = datasets.ImageFolder(os.path.join(DATA_DIR, 'test'), transform=transform)\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "# val_loader   = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "# test_loader  = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "# ============================\n",
    "# âœ… Model Definition\n",
    "# ============================\n",
    "\n",
    "\n",
    "# # mFrom here \n",
    "class CustomEfficientNetV2(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CustomEfficientNetV2, self).__init__()\n",
    "        \n",
    "        # EfficientNetV2 model (small, medium, or large)\n",
    "        # Use 'weights=models.EfficientNet_V2_S_Weights.DEFAULT' to load pre-trained weights\n",
    "        self.base_model = models.efficientnet_v2_s(weights=models.EfficientNet_V2_S_Weights.DEFAULT)  # You can swap to _m or _l\n",
    "\n",
    "        # Replace ONLY the final classification layer\n",
    "        in_features = self.base_model.classifier[1].in_features\n",
    "        self.base_model.classifier[1] = nn.Linear(in_features, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.base_model(x)\n",
    "\n",
    "# Usage\n",
    "model = CustomEfficientNetV2(num_classes=NUM_CLASSES).to(DEVICE)\n",
    "\n",
    "\n",
    "# ============================\n",
    "# âœ… Loss and Optimizer\n",
    "# ============================\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# ============================\n",
    "# âœ… Training and Validation Loop\n",
    "# ============================\n",
    "\n",
    "\n",
    "# Store metrics for plotting\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "test_accuracy = None  # Final test accuracy\n",
    "\n",
    "\n",
    "\n",
    "def train_epoch(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    loop = tqdm(loader, desc=\"Training\", leave=False)\n",
    "    for images, labels in loop:\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "        loop.set_postfix(loss=loss.item(), acc=100. * correct / total)\n",
    "\n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "def validate_epoch(model, loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        loop = tqdm(loader, desc=\"Validation\", leave=False)\n",
    "        for images, labels in loop:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            loop.set_postfix(loss=loss.item(), acc=100. * correct / total)\n",
    "\n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "# ============================\n",
    "# âœ… Run Training\n",
    "# ============================\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\nðŸŒŸ Epoch {epoch+1}/{EPOCHS}\")\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, optimizer, criterion)\n",
    "    val_loss, val_acc = validate_epoch(model, val_loader, criterion)\n",
    "\n",
    "    # Save metrics\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_acc)\n",
    "\n",
    "    \n",
    "    print(f\"\\nðŸ“ˆ Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f} | Val Loss: {val_loss:.4f}, Acc: {val_acc:.4f}\")\n",
    "\n",
    "# ============================\n",
    "# âœ… Testing\n",
    "# ============================\n",
    "def test_model(model, loader):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader, desc=\"Testing\"):\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    acc = 100. * correct / total\n",
    "    print(f\"\\nâœ… Test Accuracy: {acc:.2f}%\")\n",
    "    return acc  # <- Return value for test_accuracy\n",
    "\n",
    "total_time_end = time.time() - total_time_start\n",
    "hours = total_time_end / 3600\n",
    "\n",
    "# Run test\n",
    "print(\"\\nðŸš€ Testing best model...\")\n",
    "test_accuracy = test_model(model, test_loader)\n",
    "\n",
    "print(f\"Total runtime: {hours:.4f} hours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cf0c350-bae6-4182-a63b-56deecb64144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model saved as 'best_model8_1.pth'\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'best_model8_1.pth')\n",
    "print(\"âœ… Model saved as 'best_model8_1.pth'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cf7a3a-f65b-49c3-9e62-49c822b81c3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4c3019-1558-4161-a623-a64f27768bc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f109fae2-cd51-4803-83a3-e5f6cbaeb69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸš€ Testing best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž         | 723/1054 [00:51<00:23, 14.18it/s]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from torchvision import models\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ============================\n",
    "# âœ… Configuration\n",
    "# ============================\n",
    "NUM_CLASSES = 2\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ============================\n",
    "# âœ… Model Definition (Matching Training)\n",
    "# ============================\n",
    "class CustomEfficientNetV2(nn.Module):\n",
    "    def __init__(self, num_classes=NUM_CLASSES):\n",
    "        super(CustomEfficientNetV2, self).__init__()\n",
    "        self.base_model = models.efficientnet_v2_s(weights=models.EfficientNet_V2_S_Weights.DEFAULT)\n",
    "\n",
    "        # Replace only the final classification layer\n",
    "        in_features = self.base_model.classifier[1].in_features\n",
    "        self.base_model.classifier[1] = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.base_model(x)\n",
    "\n",
    "\n",
    "# ============================\n",
    "# âœ… Load the Model\n",
    "# ============================\n",
    "model8_1 = CustomEfficientNetV2(num_classes=NUM_CLASSES).to(DEVICE)\n",
    "model8_1.load_state_dict(torch.load(\"best_model8_1.pth\"))\n",
    "model8_1.eval()\n",
    "\n",
    "# ============================\n",
    "# âœ… Testing Function\n",
    "# ============================\n",
    "def test_model8_1(model, loader):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader, desc=\"Testing\"):\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    acc = 100. * correct / total\n",
    "    print(f\"\\nâœ… Test Accuracy: {acc:.2f}%\")\n",
    "\n",
    "    # ðŸ“Š Confusion Matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot(cmap='Blues', values_format='d')\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.grid(False)\n",
    "    plt.show()\n",
    "\n",
    "    # ðŸ“‹ Classification Report\n",
    "    print(\"\\nðŸ“Š Classification Report:\")\n",
    "    print(classification_report(all_labels, all_preds, digits=4))\n",
    "\n",
    "# ============================\n",
    "# âœ… Run the Test\n",
    "# ============================\n",
    "print(\"\\nðŸš€ Testing best model...\")\n",
    "test_model8_1(model8_1, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df6127e-1b79-4573-ae3d-c6752fdbf9c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561fa5d0-c9f2-49e0-ba03-b9c43ca507da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the Seaborn â€œdarkgridâ€ theme\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "\n",
    "# Now your original plotting code works:\n",
    "epochs_range = range(1, EPOCHS + 1)\n",
    "\n",
    "# ðŸ”¹ Plot Loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs_range, train_losses, label='Train Loss')\n",
    "plt.plot(epochs_range, val_losses,   label='Val Loss')\n",
    "plt.title('Loss over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ðŸ”¹ Plot Accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs_range, [a * 100 for a in train_accuracies], label='Train Acc')\n",
    "plt.plot(epochs_range, [a * 100 for a in val_accuracies],   label='Val Acc')\n",
    "plt.title('Accuracy over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c2b8f0-3eb8-41e1-bb1b-4753ea3cd6fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c45c468-b34b-4910-bbd5-57309a1ac548",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111dbbb9-93ea-4526-bb37-d3ff3951a5bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b5022f-b3e0-4ca2-bb80-744b6dd7a341",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dddb0f1-eeb7-4302-81db-d4fccecde5c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19134596-f927-4020-bb03-4a113930b9db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58950e63-51ce-4400-9bbc-7de002b468ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3363eacf-6da7-4c62-8fe5-77da1d74d95a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefeaddb-ef73-440a-bb39-e4a403b25d33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3cc77c-1e12-453d-ac43-ec6b5e91ff75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
