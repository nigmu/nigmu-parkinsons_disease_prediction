{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4b1b1f3-220c-435b-95b1-243900167346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing train set...\n",
      "Processing val set...\n",
      "Processing test set...\n",
      "\n",
      "ðŸ“Š Final Verification:\n",
      "TRAIN - 41744 images\n",
      "Sample patient folders: ['HC', 'PD']\n",
      "VAL - 13509 images\n",
      "Sample patient folders: ['HC', 'PD']\n",
      "TEST - 8929 images\n",
      "Sample patient folders: ['HC', 'PD']\n",
      "\n",
      "âœ… Dataset organized with strict patient-level splits!\n"
     ]
    }
   ],
   "source": [
    "# #MDVR RGB Split\n",
    "\n",
    "\n",
    "# import os\n",
    "# import shutil\n",
    "# import pandas as pd\n",
    "# from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "# # Configuration\n",
    "# # SOURCE_ROOT = r\"C:\\NPersonal\\Projects\\SDP\\Prediction Stuff\\Dataset\\MDVR Spectrogram Dataset\"\n",
    "# # DEST_ROOT = r\"C:\\NPersonal\\Projects\\SDP\\Prediction Stuff\\Dataset\\MDVR\"\n",
    "\n",
    "# SOURCE_ROOT = r\"/home/nigmu/NPersonal/Projects/SDP/nigmu-parkinsons_disease_prediction/Dataset/MDVR RGB Spectrogram Dataset\"\n",
    "# DEST_ROOT = r\"/home/nigmu/NPersonal/Projects/SDP/nigmu-parkinsons_disease_prediction/Dataset/MDVR RGB\"\n",
    "\n",
    "# SPLIT_RATIO = (0.7, 0.15, 0.15)  # Train, Val, Test\n",
    "# SEED = 42\n",
    "\n",
    "# def extract_patient_number(folder_name):\n",
    "#     \"\"\"Extract base patient number from complex folder names\"\"\"\n",
    "#     # Example: \"S_ID00_hc_0_0_0\" -> \"ID00\"\n",
    "#     # Example: \"R_PD_123_1_2\" -> \"PD_123\"\n",
    "#     parts = folder_name.split('_')\n",
    "#     if parts[0] in ['S', 'R']:\n",
    "#         base_parts = parts[1:-3]  # Remove S/R prefix and numeric suffixes\n",
    "#     else:\n",
    "#         base_parts = parts[:-3]  # For non-S/R prefixed patients\n",
    "#     return '_'.join(base_parts)\n",
    "\n",
    "# def process_dataset():\n",
    "#     # Collect all patients with their base numbers\n",
    "#     patients = []\n",
    "    \n",
    "#     for class_name in ['HC', 'PD']:\n",
    "#         class_path = os.path.join(SOURCE_ROOT, class_name)\n",
    "#         if not os.path.exists(class_path):\n",
    "#             continue\n",
    "            \n",
    "#         for folder in os.listdir(class_path):\n",
    "#             folder_path = os.path.join(class_path, folder)\n",
    "#             if os.path.isdir(folder_path):\n",
    "#                 base_number = extract_patient_number(folder)\n",
    "#                 patients.append({\n",
    "#                     'original_path': folder_path,\n",
    "#                     'class': class_name,\n",
    "#                     'base_number': base_number,\n",
    "#                     'full_name': folder\n",
    "#                 })\n",
    "\n",
    "#     # Create DataFrame and group by base number\n",
    "#     df = pd.DataFrame(patients)\n",
    "#     grouped = df.groupby(['base_number', 'class'])\n",
    "\n",
    "#     # Prepare data for splitting\n",
    "#     unique_patients = []\n",
    "#     for (base_num, cls), group in grouped:\n",
    "#         unique_patients.append({\n",
    "#             'base_number': base_num,\n",
    "#             'class': cls,\n",
    "#             'paths': group['original_path'].tolist(),\n",
    "#             'count': len(group)\n",
    "#         })\n",
    "\n",
    "#     # Convert to DataFrame for splitting\n",
    "#     split_df = pd.DataFrame(unique_patients)\n",
    "\n",
    "#     # Split patients into train/val/test\n",
    "#     gss = GroupShuffleSplit(n_splits=1, test_size=SPLIT_RATIO[1]+SPLIT_RATIO[2], random_state=SEED)\n",
    "#     train_idx, temp_idx = next(gss.split(split_df, groups=split_df['base_number']))\n",
    "\n",
    "#     gss_val_test = GroupShuffleSplit(n_splits=1, test_size=SPLIT_RATIO[2]/(SPLIT_RATIO[1]+SPLIT_RATIO[2]), random_state=SEED)\n",
    "#     val_idx, test_idx = next(gss_val_test.split(split_df.iloc[temp_idx], groups=split_df.iloc[temp_idx]['base_number']))\n",
    "\n",
    "#     # Create splits\n",
    "#     splits = {\n",
    "#         'train': split_df.iloc[train_idx],\n",
    "#         'val': split_df.iloc[temp_idx].iloc[val_idx],\n",
    "#         'test': split_df.iloc[temp_idx].iloc[test_idx]\n",
    "#     }\n",
    "\n",
    "#     # Copy files while preserving S/R versions\n",
    "#     for split_name, split_data in splits.items():\n",
    "#         print(f\"Processing {split_name} set...\")\n",
    "#         for _, patient in split_data.iterrows():\n",
    "#             for version_path in patient['paths']:\n",
    "#                 # Create destination path\n",
    "#                 dest_folder = os.path.join(\n",
    "#                     DEST_ROOT,\n",
    "#                     split_name,\n",
    "#                     patient['class'],\n",
    "#                     os.path.basename(version_path)  # Keep original folder name\n",
    "#                 )\n",
    "                \n",
    "#                 os.makedirs(dest_folder, exist_ok=True)\n",
    "                \n",
    "#                 # Copy all PNG files\n",
    "#                 for file in os.listdir(version_path):\n",
    "#                     if file.lower().endswith('.png'):\n",
    "#                         src = os.path.join(version_path, file)\n",
    "#                         dst = os.path.join(dest_folder, file)\n",
    "#                         if not os.path.exists(dst):\n",
    "#                             shutil.copy2(src, dst)\n",
    "\n",
    "#     # Verification\n",
    "#     print(\"\\nðŸ“Š Final Verification:\")\n",
    "#     for split in ['train', 'val', 'test']:\n",
    "#         split_path = os.path.join(DEST_ROOT, split)\n",
    "#         total = 0\n",
    "#         for root, dirs, files in os.walk(split_path):\n",
    "#             total += len(files)\n",
    "#         print(f\"{split.upper()} - {total} images\")\n",
    "#         print(f\"Sample patient folders: {os.listdir(split_path)[:2]}\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     process_dataset()\n",
    "#     print(\"\\nâœ… Dataset organized with strict patient-level splits!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8328fecf-0f3b-495a-a39f-a80819fbf94c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e339b08d-6591-4914-822d-1b93b32a1dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing train for HC...\n",
      "Processing val for HC...\n",
      "Processing test for HC...\n",
      "Processing train for PD...\n",
      "Processing val for PD...\n",
      "Processing test for PD...\n",
      "TRAIN - 82983 images\n",
      "VAL - 22311 images\n",
      "TEST - 7972 images\n",
      "\n",
      "âœ… Italian dataset split successfully with unique filenames!\n"
     ]
    }
   ],
   "source": [
    "# #ITALIAN RGB Split\n",
    "\n",
    "\n",
    "# import os\n",
    "# import shutil\n",
    "# import random\n",
    "\n",
    "# # Configuration\n",
    "# SOURCE_ROOT = \"/home/nigmu/NPersonal/Projects/SDP/nigmu-parkinsons_disease_prediction/Dataset/Italian Spectrogram 3\"\n",
    "# DEST_ROOT = \"/home/nigmu/NPersonal/Projects/SDP/nigmu-parkinsons_disease_prediction/Dataset/Italian RGB 3\"\n",
    "\n",
    "# SPLIT_RATIO = (0.7, 0.10, 0.10)  # Train, Val, Test\n",
    "# random.seed(35)\n",
    "\n",
    "# # Step 1: Collect patient data\n",
    "# patients = {\"HC\": [], \"PD\": []}\n",
    "\n",
    "# for class_name in [\"HC\", \"PD\"]:\n",
    "#     class_path = os.path.join(SOURCE_ROOT, class_name)\n",
    "#     if os.path.exists(class_path):\n",
    "#         patients[class_name] = [os.path.join(class_path, p) for p in os.listdir(class_path) if os.path.isdir(os.path.join(class_path, p))]\n",
    "\n",
    "# # Step 2: Split patients into train, val, test\n",
    "# for class_name, patient_list in patients.items():\n",
    "#     random.shuffle(patient_list)\n",
    "#     total = len(patient_list)\n",
    "    \n",
    "#     train_split = int(total * SPLIT_RATIO[0])\n",
    "#     val_split = int(total * SPLIT_RATIO[1])\n",
    "\n",
    "#     splits = {\n",
    "#         \"train\": patient_list[:train_split],\n",
    "#         \"val\": patient_list[train_split:train_split + val_split],\n",
    "#         \"test\": patient_list[train_split + val_split:]\n",
    "#     }\n",
    "\n",
    "#     # ==== NEW: ensure val is the larger of val/test ====\n",
    "#     if len(splits[\"test\"]) > len(splits[\"val\"]):\n",
    "#         splits[\"val\"], splits[\"test\"] = splits[\"test\"], splits[\"val\"]\n",
    "\n",
    "#     # Step 3: Copy files with unique names\n",
    "#     for split_name, patient_folders in splits.items():\n",
    "#         print(f\"Processing {split_name} for {class_name}...\")\n",
    "\n",
    "#         for patient_folder in patient_folders:\n",
    "#             patient_name = os.path.basename(patient_folder).replace(\" \", \"_\")  # Ensure safe folder names\n",
    "#             dest_patient_folder = os.path.join(DEST_ROOT, split_name, class_name, patient_name)\n",
    "#             os.makedirs(dest_patient_folder, exist_ok=True)\n",
    "\n",
    "#             for session_folder in os.listdir(patient_folder):\n",
    "#                 session_path = os.path.join(patient_folder, session_folder)\n",
    "#                 if os.path.isdir(session_path):\n",
    "#                     # Iterate through images and rename uniquely\n",
    "#                     for idx, file in enumerate(sorted(os.listdir(session_path)), start=1):\n",
    "#                         if file.lower().endswith('.png'):\n",
    "#                             new_filename = f\"{session_folder}_{idx}.png\"  # Unique name based on session\n",
    "#                             src = os.path.join(session_path, file)\n",
    "#                             dst = os.path.join(dest_patient_folder, new_filename)\n",
    "#                             shutil.copy2(src, dst)\n",
    "\n",
    "# # Step 4: Verification\n",
    "# for split in [\"train\", \"val\", \"test\"]:\n",
    "#     split_path = os.path.join(DEST_ROOT, split)\n",
    "#     total = sum([len(files) for _, _, files in os.walk(split_path)])\n",
    "#     print(f\"{split.upper()} - {total} images\")\n",
    "\n",
    "# print(\"\\nâœ… Italian dataset split successfully with unique filenames!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0757e09d-896a-46dd-89a0-91a612d054a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95c9d31-64e8-4361-b50a-60dc65ef042c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ab5880-b7cd-419b-8664-67dff0d2e03c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86e1e50-8460-42d8-85ed-91b452ed6eed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4268d3da-df38-4532-be71-009405941a45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c66c5c6-74c2-46b3-9a3d-185da9253449",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44436f6c-9221-4b65-87b8-0247158eaeb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing train with 41 patients...\n",
      "Processing val with 10 patients...\n",
      "Processing test with 10 patients...\n",
      "TRAIN - 79613 images\n",
      "VAL - 16792 images\n",
      "TEST - 16861 images\n",
      "\n",
      "âœ… Italian dataset split successfully with as even image counts as possible!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Configuration\n",
    "SOURCE_ROOT = \"/home/nigmu/NPersonal/Projects/SDP/nigmu-parkinsons_disease_prediction/Dataset/Italian Spectrogram 30hopLength\"\n",
    "DEST_ROOT = \"/home/nigmu/NPersonal/Projects/SDP/nigmu-parkinsons_disease_prediction/Dataset/Italian RGB 3\"\n",
    "\n",
    "SPLIT_RATIO = (0.7, 0.15, 0.15)  # Train, Val, Test\n",
    "random.seed(40)\n",
    "\n",
    "# Step 1: Collect patient data\n",
    "patients = {\"HC\": [], \"PD\": []}\n",
    "\n",
    "for class_name in [\"HC\", \"PD\"]:\n",
    "    class_path = os.path.join(SOURCE_ROOT, class_name)\n",
    "    if os.path.exists(class_path):\n",
    "        patients[class_name] = [os.path.join(class_path, p) for p in os.listdir(class_path) if os.path.isdir(os.path.join(class_path, p))]\n",
    "\n",
    "# Helper functions\n",
    "def patient_image_count(patient_folder):\n",
    "    count = 0\n",
    "    for session_folder in os.listdir(patient_folder):\n",
    "        session_path = os.path.join(patient_folder, session_folder)\n",
    "        if os.path.isdir(session_path):\n",
    "            count += len([f for f in os.listdir(session_path) if f.lower().endswith('.png')])\n",
    "    return count\n",
    "\n",
    "def total_images(patient_folders):\n",
    "    return sum([patient_image_count(p) for p in patient_folders])\n",
    "\n",
    "# Step 2: Initial random split (by patient counts)\n",
    "splits = {\"train\": [], \"val\": [], \"test\": []}\n",
    "\n",
    "for class_name, patient_list in patients.items():\n",
    "    random.shuffle(patient_list)\n",
    "    total = len(patient_list)\n",
    "    train_split = int(total * SPLIT_RATIO[0])\n",
    "    val_split = int(total * SPLIT_RATIO[1])\n",
    "\n",
    "    class_splits = {\n",
    "        \"train\": patient_list[:train_split],\n",
    "        \"val\": patient_list[train_split:train_split + val_split],\n",
    "        \"test\": patient_list[train_split + val_split:]\n",
    "    }\n",
    "\n",
    "    for split_name, patient_folders in class_splits.items():\n",
    "        splits[split_name].extend(patient_folders)\n",
    "\n",
    "# Step 3: Refine splits based on actual image counts\n",
    "all_patients = splits[\"train\"] + splits[\"val\"] + splits[\"test\"]\n",
    "ideal_total = total_images(all_patients)\n",
    "\n",
    "ideal_counts = {\n",
    "    \"train\": ideal_total * SPLIT_RATIO[0],\n",
    "    \"val\": ideal_total * SPLIT_RATIO[1],\n",
    "    \"test\": ideal_total * SPLIT_RATIO[2],\n",
    "}\n",
    "\n",
    "# Continue shifting until close enough\n",
    "def current_counts(splits):\n",
    "    return {k: total_images(v) for k,v in splits.items()}\n",
    "\n",
    "def find_best_patient_to_move(from_split, to_split):\n",
    "    best_diff = float('inf')\n",
    "    best_idx = None\n",
    "    for idx, patient in enumerate(splits[from_split]):\n",
    "        patient_imgs = patient_image_count(patient)\n",
    "        new_from = current[from_split] - patient_imgs\n",
    "        new_to = current[to_split] + patient_imgs\n",
    "        diff = abs(new_from - ideal_counts[from_split]) + abs(new_to - ideal_counts[to_split])\n",
    "        if diff < best_diff:\n",
    "            best_diff = diff\n",
    "            best_idx = idx\n",
    "    return best_idx\n",
    "\n",
    "# Keep refining\n",
    "threshold = 0.01 * ideal_total  # 1% tolerance\n",
    "current = current_counts(splits)\n",
    "\n",
    "while True:\n",
    "    diffs = {k: current[k] - ideal_counts[k] for k in splits.keys()}\n",
    "    too_big = [k for k in diffs if diffs[k] > threshold]\n",
    "    too_small = [k for k in diffs if diffs[k] < -threshold]\n",
    "\n",
    "    if not too_big or not too_small:\n",
    "        break  # Done\n",
    "\n",
    "    from_split = max(too_big, key=lambda k: diffs[k])\n",
    "    to_split = min(too_small, key=lambda k: diffs[k])\n",
    "\n",
    "    best_idx = find_best_patient_to_move(from_split, to_split)\n",
    "    if best_idx is None:\n",
    "        break\n",
    "\n",
    "    patient = splits[from_split].pop(best_idx)\n",
    "    splits[to_split].append(patient)\n",
    "\n",
    "    current = current_counts(splits)\n",
    "\n",
    "# Step 4: Copy files with unique names\n",
    "for split_name, patient_folders in splits.items():\n",
    "    print(f\"Processing {split_name} with {len(patient_folders)} patients...\")\n",
    "\n",
    "    for patient_folder in patient_folders:\n",
    "        patient_name = os.path.basename(patient_folder).replace(\" \", \"_\")\n",
    "        dest_patient_folder = os.path.join(DEST_ROOT, split_name, os.path.basename(os.path.dirname(patient_folder)), patient_name)\n",
    "        os.makedirs(dest_patient_folder, exist_ok=True)\n",
    "\n",
    "        for session_folder in os.listdir(patient_folder):\n",
    "            session_path = os.path.join(patient_folder, session_folder)\n",
    "            if os.path.isdir(session_path):\n",
    "                for idx, file in enumerate(sorted(os.listdir(session_path)), start=1):\n",
    "                    if file.lower().endswith('.png'):\n",
    "                        new_filename = f\"{session_folder}_{idx}.png\"\n",
    "                        src = os.path.join(session_path, file)\n",
    "                        dst = os.path.join(dest_patient_folder, new_filename)\n",
    "                        shutil.copy2(src, dst)\n",
    "\n",
    "# Step 5: Verification\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    split_path = os.path.join(DEST_ROOT, split)\n",
    "    total = sum([len(files) for _, _, files in os.walk(split_path)])\n",
    "    print(f\"{split.upper()} - {total} images\")\n",
    "\n",
    "print(\"\\nâœ… Italian dataset split successfully with as even image counts as possible!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d4b40b-a9f2-44cd-b510-55f9cc42ab88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
