{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b75f763-cf4a-44ec-8f9a-a6a8be4cd2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cc89550-1b28-4093-bbf9-bda8e85140cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing train set...\n",
      "Processing val set...\n",
      "Processing test set...\n",
      "\n",
      "ðŸ“Š Final Verification:\n",
      "TRAIN - 41744 images\n",
      "Sample patient folders: ['HC', 'PD']\n",
      "VAL - 13509 images\n",
      "Sample patient folders: ['HC', 'PD']\n",
      "TEST - 8929 images\n",
      "Sample patient folders: ['HC', 'PD']\n",
      "\n",
      "âœ… Dataset organized with strict patient-level splits!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "# Configuration\n",
    "SOURCE_ROOT = r\"C:\\NPersonal\\Projects\\SDP\\Prediction Stuff\\Dataset\\MDVR Spectrogram Dataset\"\n",
    "DEST_ROOT = r\"C:\\NPersonal\\Projects\\SDP\\Prediction Stuff\\Dataset\\MDVR\"\n",
    "SPLIT_RATIO = (0.7, 0.15, 0.15)  # Train, Val, Test\n",
    "SEED = 42\n",
    "\n",
    "def extract_patient_number(folder_name):\n",
    "    \"\"\"Extract base patient number from complex folder names\"\"\"\n",
    "    # Example: \"S_ID00_hc_0_0_0\" -> \"ID00\"\n",
    "    # Example: \"R_PD_123_1_2\" -> \"PD_123\"\n",
    "    parts = folder_name.split('_')\n",
    "    if parts[0] in ['S', 'R']:\n",
    "        base_parts = parts[1:-3]  # Remove S/R prefix and numeric suffixes\n",
    "    else:\n",
    "        base_parts = parts[:-3]  # For non-S/R prefixed patients\n",
    "    return '_'.join(base_parts)\n",
    "\n",
    "def process_dataset():\n",
    "    # Collect all patients with their base numbers\n",
    "    patients = []\n",
    "    \n",
    "    for class_name in ['HC', 'PD']:\n",
    "        class_path = os.path.join(SOURCE_ROOT, class_name)\n",
    "        if not os.path.exists(class_path):\n",
    "            continue\n",
    "            \n",
    "        for folder in os.listdir(class_path):\n",
    "            folder_path = os.path.join(class_path, folder)\n",
    "            if os.path.isdir(folder_path):\n",
    "                base_number = extract_patient_number(folder)\n",
    "                patients.append({\n",
    "                    'original_path': folder_path,\n",
    "                    'class': class_name,\n",
    "                    'base_number': base_number,\n",
    "                    'full_name': folder\n",
    "                })\n",
    "\n",
    "    # Create DataFrame and group by base number\n",
    "    df = pd.DataFrame(patients)\n",
    "    grouped = df.groupby(['base_number', 'class'])\n",
    "\n",
    "    # Prepare data for splitting\n",
    "    unique_patients = []\n",
    "    for (base_num, cls), group in grouped:\n",
    "        unique_patients.append({\n",
    "            'base_number': base_num,\n",
    "            'class': cls,\n",
    "            'paths': group['original_path'].tolist(),\n",
    "            'count': len(group)\n",
    "        })\n",
    "\n",
    "    # Convert to DataFrame for splitting\n",
    "    split_df = pd.DataFrame(unique_patients)\n",
    "\n",
    "    # Split patients into train/val/test\n",
    "    gss = GroupShuffleSplit(n_splits=1, test_size=SPLIT_RATIO[1]+SPLIT_RATIO[2], random_state=SEED)\n",
    "    train_idx, temp_idx = next(gss.split(split_df, groups=split_df['base_number']))\n",
    "\n",
    "    gss_val_test = GroupShuffleSplit(n_splits=1, test_size=SPLIT_RATIO[2]/(SPLIT_RATIO[1]+SPLIT_RATIO[2]), random_state=SEED)\n",
    "    val_idx, test_idx = next(gss_val_test.split(split_df.iloc[temp_idx], groups=split_df.iloc[temp_idx]['base_number']))\n",
    "\n",
    "    # Create splits\n",
    "    splits = {\n",
    "        'train': split_df.iloc[train_idx],\n",
    "        'val': split_df.iloc[temp_idx].iloc[val_idx],\n",
    "        'test': split_df.iloc[temp_idx].iloc[test_idx]\n",
    "    }\n",
    "\n",
    "    # Copy files while preserving S/R versions\n",
    "    for split_name, split_data in splits.items():\n",
    "        print(f\"Processing {split_name} set...\")\n",
    "        for _, patient in split_data.iterrows():\n",
    "            for version_path in patient['paths']:\n",
    "                # Create destination path\n",
    "                dest_folder = os.path.join(\n",
    "                    DEST_ROOT,\n",
    "                    split_name,\n",
    "                    patient['class'],\n",
    "                    os.path.basename(version_path)  # Keep original folder name\n",
    "                )\n",
    "                \n",
    "                os.makedirs(dest_folder, exist_ok=True)\n",
    "                \n",
    "                # Copy all PNG files\n",
    "                for file in os.listdir(version_path):\n",
    "                    if file.lower().endswith('.png'):\n",
    "                        src = os.path.join(version_path, file)\n",
    "                        dst = os.path.join(dest_folder, file)\n",
    "                        if not os.path.exists(dst):\n",
    "                            shutil.copy2(src, dst)\n",
    "\n",
    "    # Verification\n",
    "    print(\"\\nðŸ“Š Final Verification:\")\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        split_path = os.path.join(DEST_ROOT, split)\n",
    "        total = 0\n",
    "        for root, dirs, files in os.walk(split_path):\n",
    "            total += len(files)\n",
    "        print(f\"{split.upper()} - {total} images\")\n",
    "        print(f\"Sample patient folders: {os.listdir(split_path)[:2]}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_dataset()\n",
    "    print(\"\\nâœ… Dataset organized with strict patient-level splits!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001aa4ba-1383-4846-b1b3-26b4c87866fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 41744 samples for train split\n",
      "Loaded 13509 samples for val split\n",
      "Loaded 8929 samples for test split\n",
      "Using device: cuda\n",
      "Training with augmentation: mixed_freq_mask\n",
      "Epoch 1/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1305/1305 [09:29<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.8301 Acc: 0.6069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 423/423 [03:53<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.5135 Acc: 0.7816\n",
      "Epoch 2/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1305/1305 [07:37<00:00,  2.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6286 Acc: 0.6392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 423/423 [01:07<00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.6024 Acc: 0.7539\n",
      "Epoch 3/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                     | 159/1305 [03:02<20:06,  1.05s/it]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed()\n",
    "\n",
    "# Custom dataset class for MDVR dataset\n",
    "class MDVRDataset(Dataset):\n",
    "    def __init__(self, root_dir, split='train', transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directory with all the data.\n",
    "            split (string): 'train', 'test', or 'val'\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.split = split\n",
    "        self.transform = transform\n",
    "        self.classes = ['hc', 'pd']  # healthy control, Parkinson's disease\n",
    "        self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}\n",
    "        \n",
    "        self.samples = []\n",
    "        self._load_data()\n",
    "        \n",
    "    def _load_data(self):\n",
    "        split_dir = os.path.join(self.root_dir, self.split)\n",
    "        for class_name in self.classes:\n",
    "            class_idx = self.class_to_idx[class_name]\n",
    "            class_dir = os.path.join(split_dir, class_name)\n",
    "            \n",
    "            # Iterate through patient folders\n",
    "            for patient_folder in os.listdir(class_dir):\n",
    "                patient_path = os.path.join(class_dir, patient_folder)\n",
    "                if os.path.isdir(patient_path):\n",
    "                    # Iterate through image files in patient folder\n",
    "                    for img_name in os.listdir(patient_path):\n",
    "                        if img_name.endswith(('.png', '.jpg', '.jpeg')):\n",
    "                            img_path = os.path.join(patient_path, img_name)\n",
    "                            self.samples.append((img_path, class_idx, patient_folder))\n",
    "        \n",
    "        print(f\"Loaded {len(self.samples)} samples for {self.split} split\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path, class_idx, patient_id = self.samples[idx]\n",
    "        \n",
    "        # Load image\n",
    "        # image = Image.open(img_path).convert('RGB')\n",
    "        image = Image.open(img_path).convert('L')  # Convert to grayscale\n",
    "\n",
    "        \n",
    "        # Apply transforms if any\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, class_idx, patient_id\n",
    "\n",
    "\n",
    "# Augmentation techniques based on the paper\n",
    "\n",
    "# 1. Frequency Masking\n",
    "class FrequencyMasking:\n",
    "    def __init__(self, max_width=30, num_masks=1):\n",
    "        self.max_width = max_width\n",
    "        self.num_masks = num_masks\n",
    "        \n",
    "    def __call__(self, img):\n",
    "        img_tensor = transforms.ToTensor()(img)\n",
    "        _, h, w = img_tensor.shape\n",
    "        \n",
    "        for _ in range(self.num_masks):\n",
    "            f = np.random.randint(0, self.max_width)\n",
    "            f0 = np.random.randint(0, h - f)\n",
    "            \n",
    "            # Apply frequency mask\n",
    "            img_tensor[:, f0:f0+f, :] = 0\n",
    "        \n",
    "        return transforms.ToPILImage()(img_tensor)\n",
    "\n",
    "# 2. Mixup\n",
    "class Mixup:\n",
    "    def __init__(self, alpha=0.2):\n",
    "        self.alpha = alpha\n",
    "        \n",
    "    def __call__(self, batch_x, batch_y):\n",
    "        \"\"\"Apply mixup to a batch of images and labels\"\"\"\n",
    "        lam = np.random.beta(self.alpha, self.alpha)\n",
    "        batch_size = batch_x.size(0)\n",
    "        index = torch.randperm(batch_size).to(batch_x.device)\n",
    "        \n",
    "        mixed_x = lam * batch_x + (1 - lam) * batch_x[index]\n",
    "        y_a, y_b = batch_y, batch_y[index]\n",
    "        \n",
    "        return mixed_x, y_a, y_b, lam\n",
    "\n",
    "# 3. Mixed Frequency Masking\n",
    "class MixedFrequencyMasking:\n",
    "    def __init__(self, max_width=30, num_masks=1):\n",
    "        self.max_width = max_width\n",
    "        self.num_masks = num_masks\n",
    "    \n",
    "    def __call__(self, batch_x, batch_y):\n",
    "        \"\"\"Apply mixed frequency masking to a batch of images and labels\"\"\"\n",
    "        batch_size = batch_x.size(0)\n",
    "        device = batch_x.device\n",
    "        _, h, w = batch_x[0].shape\n",
    "        \n",
    "        # Create copies for mixing\n",
    "        mixed_x = batch_x.clone()\n",
    "        \n",
    "        # For storing mixing ratios\n",
    "        mixing_ratios = torch.ones(batch_size, device=device)\n",
    "        \n",
    "        # For each image in the batch\n",
    "        for i in range(batch_size):\n",
    "            # Select another random image to mix with\n",
    "            j = (i + torch.randint(1, batch_size, (1,)).item()) % batch_size\n",
    "            \n",
    "            # Apply frequency replacements\n",
    "            total_freq_replaced = 0\n",
    "            \n",
    "            for _ in range(self.num_masks):\n",
    "                # Random frequency mask width\n",
    "                f = torch.randint(1, self.max_width + 1, (1,)).item()\n",
    "                # Random starting frequency\n",
    "                f0 = torch.randint(0, h - f, (1,)).item()\n",
    "                \n",
    "                # Replace frequency band in image i with the same band from image j\n",
    "                mixed_x[i, :, f0:f0+f, :] = batch_x[j, :, f0:f0+f, :]\n",
    "                \n",
    "                # Accumulate total frequency replaced\n",
    "                total_freq_replaced += f\n",
    "            \n",
    "            # Calculate mixing ratio based on proportion of frequency replaced\n",
    "            mixing_ratio = total_freq_replaced / h\n",
    "            mixing_ratios[i] = 1 - mixing_ratio\n",
    "            \n",
    "        # Get indices for mixing labels\n",
    "        indices = torch.remainder(torch.arange(batch_size) + 1, batch_size).to(device)\n",
    "        y_a, y_b = batch_y, batch_y[indices]\n",
    "        \n",
    "        return mixed_x, y_a, y_b, mixing_ratios\n",
    "\n",
    "# Custom CNN model\n",
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(CustomCNN, self).__init__()\n",
    "        # Input size: 3x496x200\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)  # 32x248x100\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)  # 64x124x50\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)  # 128x62x25\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)  # 256x31x12\n",
    "        \n",
    "        # Calculate flattened size\n",
    "        self.flat_size = 256 * 31 * 12\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(self.flat_size, 512)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc3 = nn.Linear(128, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Convolutional layers\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.pool3(x)\n",
    "        \n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = self.pool4(x)\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(-1, self.flat_size)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Training function with augmentation\n",
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, device='cuda', \n",
    "                use_mixup=False, use_mixed_freq_mask=False):\n",
    "    \"\"\"\n",
    "    Training function with support for different augmentation techniques\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    \n",
    "    # Initialize mixup and mixed frequency masking if used\n",
    "    mixup_fn = Mixup(alpha=0.2) if use_mixup else None\n",
    "    mixed_freq_mask_fn = MixedFrequencyMasking(max_width=30, num_masks=1) if use_mixed_freq_mask else None\n",
    "    \n",
    "    best_acc = 0.0\n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        print('-' * 10)\n",
    "        \n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "                \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            \n",
    "            # Iterate over data\n",
    "            for inputs, labels, _ in tqdm(dataloaders[phase]):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # Forward pass\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Apply augmentation techniques during training\n",
    "                    if phase == 'train':\n",
    "                        if use_mixup:\n",
    "                            inputs, labels_a, labels_b, lam = mixup_fn(inputs, labels)\n",
    "                            outputs = model(inputs)\n",
    "                            loss = lam * criterion(outputs, labels_a) + (1 - lam) * criterion(outputs, labels_b)\n",
    "                        elif use_mixed_freq_mask:\n",
    "                            inputs, labels_a, labels_b, mixing_ratios = mixed_freq_mask_fn(inputs, labels)\n",
    "                            outputs = model(inputs)\n",
    "                            # Apply per-sample mixing ratios\n",
    "                            batch_loss = 0\n",
    "                            for i in range(inputs.size(0)):\n",
    "                                ratio = mixing_ratios[i]\n",
    "                                batch_loss += ratio * criterion(outputs[i:i+1], labels_a[i:i+1]) + \\\n",
    "                                             (1 - ratio) * criterion(outputs[i:i+1], labels_b[i:i+1])\n",
    "                            loss = batch_loss / inputs.size(0)\n",
    "                        else:\n",
    "                            outputs = model(inputs)\n",
    "                            loss = criterion(outputs, labels)\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    \n",
    "                    # Backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                \n",
    "                # Statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "            \n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "            \n",
    "            # Record history\n",
    "            if phase == 'train':\n",
    "                history['train_loss'].append(epoch_loss)\n",
    "                history['train_acc'].append(epoch_acc.item())\n",
    "            else:\n",
    "                history['val_loss'].append(epoch_loss)\n",
    "                history['val_acc'].append(epoch_acc.item())\n",
    "                \n",
    "                # Save best model\n",
    "                if epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "                    torch.save(model.state_dict(), 'best_model.pth')\n",
    "                    \n",
    "    print(f'Best val Acc: {best_acc:.4f}')\n",
    "    \n",
    "    # Load best model weights\n",
    "    model.load_state_dict(torch.load('best_model.pth'))\n",
    "    return model, history\n",
    "\n",
    "# Function to test the model\n",
    "def test_model(model, test_loader, criterion, device='cuda'):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    \n",
    "    # For confusion matrix\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels, _ in tqdm(test_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    test_loss = running_loss / len(test_loader.dataset)\n",
    "    test_acc = running_corrects.double() / len(test_loader.dataset)\n",
    "    \n",
    "    print(f'Test Loss: {test_loss:.4f} Acc: {test_acc:.4f}')\n",
    "    \n",
    "    return test_loss, test_acc, all_preds, all_labels\n",
    "\n",
    "# Main execution function\n",
    "def run_experiment(data_dir, batch_size=32, num_epochs=50, use_augmentation='mixed_freq_mask'):\n",
    "    \"\"\"\n",
    "    Run the complete experiment\n",
    "    Args:\n",
    "        data_dir: Root directory of the MDVR dataset\n",
    "        batch_size: Batch size for training\n",
    "        num_epochs: Number of training epochs\n",
    "        use_augmentation: Type of augmentation to use ('none', 'mixup', 'freq_mask', 'mixed_freq_mask')\n",
    "    \"\"\"\n",
    "    # Define transforms\n",
    "    # Base transform (no augmentation)\n",
    "    \n",
    "    # base_transform = transforms.Compose([\n",
    "    #     transforms.Resize((496, 200)),\n",
    "    #     transforms.ToTensor(),\n",
    "    #     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    # ])\n",
    "\n",
    "    base_transform = transforms.Compose([\n",
    "        transforms.Resize((496, 200)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5], std=[0.5])  # Single channel normalization\n",
    "    ])\n",
    "    \n",
    "    \n",
    "    # Transform with frequency masking\n",
    "    # freq_mask_transform = transforms.Compose([\n",
    "    #     transforms.Resize((496, 200)),\n",
    "    #     FrequencyMasking(max_width=30, num_masks=1),\n",
    "    #     transforms.ToTensor(),\n",
    "    #     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "    # ])\n",
    "\n",
    "    freq_mask_transform = transforms.Compose([\n",
    "        transforms.Resize((496, 200)),\n",
    "        FrequencyMasking(max_width=30, num_masks=1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5], std=[0.5])  # Single channel normalization\n",
    "    ])\n",
    "    \n",
    "    # Choose the appropriate transform based on augmentation type\n",
    "    if use_augmentation == 'freq_mask':\n",
    "        train_transform = freq_mask_transform\n",
    "    else:\n",
    "        train_transform = base_transform\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = MDVRDataset(data_dir, split='train', transform=train_transform)\n",
    "    val_dataset = MDVRDataset(data_dir, split='val', transform=base_transform)\n",
    "    test_dataset = MDVRDataset(data_dir, split='test', transform=base_transform)\n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "    \n",
    "    dataloaders = {\n",
    "        'train': train_loader,\n",
    "        'val': val_loader\n",
    "    }\n",
    "    \n",
    "    # Create model, loss function, and optimizer\n",
    "    model = CustomCNN(num_classes=2)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Device configuration\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Set augmentation flags\n",
    "    use_mixup = (use_augmentation == 'mixup')\n",
    "    use_mixed_freq_mask = (use_augmentation == 'mixed_freq_mask')\n",
    "    \n",
    "    # Train model\n",
    "    print(f\"Training with augmentation: {use_augmentation}\")\n",
    "    model, history = train_model(\n",
    "        model, dataloaders, criterion, optimizer, \n",
    "        num_epochs=num_epochs, device=device,\n",
    "        use_mixup=use_mixup, use_mixed_freq_mask=use_mixed_freq_mask\n",
    "    )\n",
    "    \n",
    "    # Test model\n",
    "    test_loss, test_acc, all_preds, all_labels = test_model(model, test_loader, criterion, device)\n",
    "    \n",
    "    # Plot training history\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history['train_loss'], label='Training')\n",
    "    plt.plot(history['val_loss'], label='Validation')\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history['train_acc'], label='Training')\n",
    "    plt.plot(history['val_acc'], label='Validation')\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_history.png')\n",
    "    \n",
    "    return model, history, (test_loss, test_acc)\n",
    "\n",
    "# Example usage\n",
    "# To run the experiment:\n",
    "model, history, test_results = run_experiment(\n",
    "    data_dir=\"C:/NPersonal/Projects/SDP/Prediction Stuff/Dataset/MDVR\",\n",
    "    batch_size=32, \n",
    "    num_epochs=50,\n",
    "    use_augmentation='mixed_freq_mask'  # or 'none', 'mixup', 'freq_mask'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ad7017-84ee-4997-8b52-006e83a28e1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c189b274-461c-4693-9358-c76095979365",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb927e4-d4e1-4df2-b5de-ca651aa8fb74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b58853-1d8b-43aa-a737-329561c7f4ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42451f80-58d5-4d11-8b34-8a66fee6f8aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b9cc86-49a2-48df-b3f5-479f6e554d4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c0c0e1-bceb-48f9-b266-6e84b80dc2ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a3e4b9-1661-4763-9737-dc92d11aac5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7193e7fa-b6b8-492b-9155-c23b8246d399",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adceeefb-ccb1-4180-aee8-42a58e9c9cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "print(\"CuDNN version:\", torch.backends.cudnn.version() if torch.cuda.is_available() else \"No CUDA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0228b472-886e-43a8-91c7-a8ab480b74a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0645b9ec-f46c-4d60-942e-2f072207e8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def get_image_channels_pil(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    mode = image.mode\n",
    "    if mode == \"L\":\n",
    "        return 1  # Grayscale\n",
    "    elif mode == \"RGB\":\n",
    "        return 3  # RGB\n",
    "    elif mode == \"RGBA\":\n",
    "        return 4  # RGBA\n",
    "    else:\n",
    "        return f\"Unknown mode: {mode}\"\n",
    "\n",
    "image_path = \"C:/NPersonal/Projects/SDP/Prediction Stuff/Dataset/MDVR/train/HC/R_ID00_hc_0_0_0/1.png\"  # Change this to your image path\n",
    "print(\"Number of channels (PIL):\", get_image_channels_pil(image_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fe53bc-7a5d-4701-ba1e-be70b122c4f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
