{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b75f763-cf4a-44ec-8f9a-a6a8be4cd2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cc89550-1b28-4093-bbf9-bda8e85140cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'base_number'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 108\u001b[39m\n\u001b[32m    105\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSample patient folders: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos.listdir(split_path)[:\u001b[32m2\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    107\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m     \u001b[43mprocess_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    109\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mâœ… Dataset organized with strict patient-level splits!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 45\u001b[39m, in \u001b[36mprocess_dataset\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;66;03m# Create DataFrame and group by base number\u001b[39;00m\n\u001b[32m     44\u001b[39m df = pd.DataFrame(patients)\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m grouped = \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mbase_number\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mclass\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[38;5;66;03m# Prepare data for splitting\u001b[39;00m\n\u001b[32m     48\u001b[39m unique_patients = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pytorch_env/lib/python3.12/site-packages/pandas/core/frame.py:9183\u001b[39m, in \u001b[36mDataFrame.groupby\u001b[39m\u001b[34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[39m\n\u001b[32m   9180\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   9181\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mYou have to supply one of \u001b[39m\u001b[33m'\u001b[39m\u001b[33mby\u001b[39m\u001b[33m'\u001b[39m\u001b[33m and \u001b[39m\u001b[33m'\u001b[39m\u001b[33mlevel\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m9183\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   9184\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   9185\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9186\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9187\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9188\u001b[39m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9189\u001b[39m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9190\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9191\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9192\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9193\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pytorch_env/lib/python3.12/site-packages/pandas/core/groupby/groupby.py:1329\u001b[39m, in \u001b[36mGroupBy.__init__\u001b[39m\u001b[34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[39m\n\u001b[32m   1326\u001b[39m \u001b[38;5;28mself\u001b[39m.dropna = dropna\n\u001b[32m   1328\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1329\u001b[39m     grouper, exclusions, obj = \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1330\u001b[39m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1331\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1332\u001b[39m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1333\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1334\u001b[39m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1335\u001b[39m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mno_default\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1336\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1337\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1339\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib.no_default:\n\u001b[32m   1340\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping._passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper.groupings):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pytorch_env/lib/python3.12/site-packages/pandas/core/groupby/grouper.py:1043\u001b[39m, in \u001b[36mget_grouper\u001b[39m\u001b[34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[39m\n\u001b[32m   1041\u001b[39m         in_axis, level, gpr = \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1042\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1043\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[32m   1044\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr.key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1045\u001b[39m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[32m   1046\u001b[39m     exclusions.add(gpr.key)\n",
      "\u001b[31mKeyError\u001b[39m: 'base_number'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "# Configuration\n",
    "SOURCE_ROOT = r\"C:\\NPersonal\\Projects\\SDP\\Prediction Stuff\\Dataset\\MDVR Spectrogram Dataset\"\n",
    "DEST_ROOT = r\"C:\\NPersonal\\Projects\\SDP\\Prediction Stuff\\Dataset\\MDVR\"\n",
    "SPLIT_RATIO = (0.7, 0.15, 0.15)  # Train, Val, Test\n",
    "SEED = 42\n",
    "\n",
    "def extract_patient_number(folder_name):\n",
    "    \"\"\"Extract base patient number from complex folder names\"\"\"\n",
    "    # Example: \"S_ID00_hc_0_0_0\" -> \"ID00\"\n",
    "    # Example: \"R_PD_123_1_2\" -> \"PD_123\"\n",
    "    parts = folder_name.split('_')\n",
    "    if parts[0] in ['S', 'R']:\n",
    "        base_parts = parts[1:-3]  # Remove S/R prefix and numeric suffixes\n",
    "    else:\n",
    "        base_parts = parts[:-3]  # For non-S/R prefixed patients\n",
    "    return '_'.join(base_parts)\n",
    "\n",
    "def process_dataset():\n",
    "    # Collect all patients with their base numbers\n",
    "    patients = []\n",
    "    \n",
    "    for class_name in ['HC', 'PD']:\n",
    "        class_path = os.path.join(SOURCE_ROOT, class_name)\n",
    "        if not os.path.exists(class_path):\n",
    "            continue\n",
    "            \n",
    "        for folder in os.listdir(class_path):\n",
    "            folder_path = os.path.join(class_path, folder)\n",
    "            if os.path.isdir(folder_path):\n",
    "                base_number = extract_patient_number(folder)\n",
    "                patients.append({\n",
    "                    'original_path': folder_path,\n",
    "                    'class': class_name,\n",
    "                    'base_number': base_number,\n",
    "                    'full_name': folder\n",
    "                })\n",
    "\n",
    "    # Create DataFrame and group by base number\n",
    "    df = pd.DataFrame(patients)\n",
    "    grouped = df.groupby(['base_number', 'class'])\n",
    "\n",
    "    # Prepare data for splitting\n",
    "    unique_patients = []\n",
    "    for (base_num, cls), group in grouped:\n",
    "        unique_patients.append({\n",
    "            'base_number': base_num,\n",
    "            'class': cls,\n",
    "            'paths': group['original_path'].tolist(),\n",
    "            'count': len(group)\n",
    "        })\n",
    "\n",
    "    # Convert to DataFrame for splitting\n",
    "    split_df = pd.DataFrame(unique_patients)\n",
    "\n",
    "    # Split patients into train/val/test\n",
    "    gss = GroupShuffleSplit(n_splits=1, test_size=SPLIT_RATIO[1]+SPLIT_RATIO[2], random_state=SEED)\n",
    "    train_idx, temp_idx = next(gss.split(split_df, groups=split_df['base_number']))\n",
    "\n",
    "    gss_val_test = GroupShuffleSplit(n_splits=1, test_size=SPLIT_RATIO[2]/(SPLIT_RATIO[1]+SPLIT_RATIO[2]), random_state=SEED)\n",
    "    val_idx, test_idx = next(gss_val_test.split(split_df.iloc[temp_idx], groups=split_df.iloc[temp_idx]['base_number']))\n",
    "\n",
    "    # Create splits\n",
    "    splits = {\n",
    "        'train': split_df.iloc[train_idx],\n",
    "        'val': split_df.iloc[temp_idx].iloc[val_idx],\n",
    "        'test': split_df.iloc[temp_idx].iloc[test_idx]\n",
    "    }\n",
    "\n",
    "    # Copy files while preserving S/R versions\n",
    "    for split_name, split_data in splits.items():\n",
    "        print(f\"Processing {split_name} set...\")\n",
    "        for _, patient in split_data.iterrows():\n",
    "            for version_path in patient['paths']:\n",
    "                # Create destination path\n",
    "                dest_folder = os.path.join(\n",
    "                    DEST_ROOT,\n",
    "                    split_name,\n",
    "                    patient['class'],\n",
    "                    os.path.basename(version_path)  # Keep original folder name\n",
    "                )\n",
    "                \n",
    "                os.makedirs(dest_folder, exist_ok=True)\n",
    "                \n",
    "                # Copy all PNG files\n",
    "                for file in os.listdir(version_path):\n",
    "                    if file.lower().endswith('.png'):\n",
    "                        src = os.path.join(version_path, file)\n",
    "                        dst = os.path.join(dest_folder, file)\n",
    "                        if not os.path.exists(dst):\n",
    "                            shutil.copy2(src, dst)\n",
    "\n",
    "    # Verification\n",
    "    print(\"\\nðŸ“Š Final Verification:\")\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        split_path = os.path.join(DEST_ROOT, split)\n",
    "        total = 0\n",
    "        for root, dirs, files in os.walk(split_path):\n",
    "            total += len(files)\n",
    "        print(f\"{split.upper()} - {total} images\")\n",
    "        print(f\"Sample patient folders: {os.listdir(split_path)[:2]}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_dataset()\n",
    "    print(\"\\nâœ… Dataset organized with strict patient-level splits!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001aa4ba-1383-4846-b1b3-26b4c87866fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed()\n",
    "\n",
    "# Custom dataset class for MDVR dataset\n",
    "class MDVRDataset(Dataset):\n",
    "    def __init__(self, root_dir, split='train', transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directory with all the data.\n",
    "            split (string): 'train', 'test', or 'val'\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.split = split\n",
    "        self.transform = transform\n",
    "        self.classes = ['hc', 'pd']  # healthy control, Parkinson's disease\n",
    "        self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}\n",
    "        \n",
    "        self.samples = []\n",
    "        self._load_data()\n",
    "        \n",
    "    def _load_data(self):\n",
    "        split_dir = os.path.join(self.root_dir, self.split)\n",
    "        for class_name in self.classes:\n",
    "            class_idx = self.class_to_idx[class_name]\n",
    "            class_dir = os.path.join(split_dir, class_name)\n",
    "            \n",
    "            # Iterate through patient folders\n",
    "            for patient_folder in os.listdir(class_dir):\n",
    "                patient_path = os.path.join(class_dir, patient_folder)\n",
    "                if os.path.isdir(patient_path):\n",
    "                    # Iterate through image files in patient folder\n",
    "                    for img_name in os.listdir(patient_path):\n",
    "                        if img_name.endswith(('.png', '.jpg', '.jpeg')):\n",
    "                            img_path = os.path.join(patient_path, img_name)\n",
    "                            self.samples.append((img_path, class_idx, patient_folder))\n",
    "        \n",
    "        print(f\"Loaded {len(self.samples)} samples for {self.split} split\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path, class_idx, patient_id = self.samples[idx]\n",
    "        \n",
    "        # Load image\n",
    "        # image = Image.open(img_path).convert('RGB')\n",
    "        image = Image.open(img_path).convert('L')  # Convert to grayscale\n",
    "\n",
    "        \n",
    "        # Apply transforms if any\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, class_idx, patient_id\n",
    "\n",
    "\n",
    "# Augmentation techniques based on the paper\n",
    "\n",
    "# 1. Frequency Masking\n",
    "class FrequencyMasking:\n",
    "    def __init__(self, max_width=30, num_masks=1):\n",
    "        self.max_width = max_width\n",
    "        self.num_masks = num_masks\n",
    "        \n",
    "    def __call__(self, img):\n",
    "        img_tensor = transforms.ToTensor()(img)\n",
    "        _, h, w = img_tensor.shape\n",
    "        \n",
    "        for _ in range(self.num_masks):\n",
    "            f = np.random.randint(0, self.max_width)\n",
    "            f0 = np.random.randint(0, h - f)\n",
    "            \n",
    "            # Apply frequency mask\n",
    "            img_tensor[:, f0:f0+f, :] = 0\n",
    "        \n",
    "        return transforms.ToPILImage()(img_tensor)\n",
    "\n",
    "# 2. Mixup\n",
    "class Mixup:\n",
    "    def __init__(self, alpha=0.2):\n",
    "        self.alpha = alpha\n",
    "        \n",
    "    def __call__(self, batch_x, batch_y):\n",
    "        \"\"\"Apply mixup to a batch of images and labels\"\"\"\n",
    "        lam = np.random.beta(self.alpha, self.alpha)\n",
    "        batch_size = batch_x.size(0)\n",
    "        index = torch.randperm(batch_size).to(batch_x.device)\n",
    "        \n",
    "        mixed_x = lam * batch_x + (1 - lam) * batch_x[index]\n",
    "        y_a, y_b = batch_y, batch_y[index]\n",
    "        \n",
    "        return mixed_x, y_a, y_b, lam\n",
    "\n",
    "# 3. Mixed Frequency Masking\n",
    "class MixedFrequencyMasking:\n",
    "    def __init__(self, max_width=30, num_masks=1):\n",
    "        self.max_width = max_width\n",
    "        self.num_masks = num_masks\n",
    "    \n",
    "    def __call__(self, batch_x, batch_y):\n",
    "        \"\"\"Apply mixed frequency masking to a batch of images and labels\"\"\"\n",
    "        batch_size = batch_x.size(0)\n",
    "        device = batch_x.device\n",
    "        _, h, w = batch_x[0].shape\n",
    "        \n",
    "        # Create copies for mixing\n",
    "        mixed_x = batch_x.clone()\n",
    "        \n",
    "        # For storing mixing ratios\n",
    "        mixing_ratios = torch.ones(batch_size, device=device)\n",
    "        \n",
    "        # For each image in the batch\n",
    "        for i in range(batch_size):\n",
    "            # Select another random image to mix with\n",
    "            j = (i + torch.randint(1, batch_size, (1,)).item()) % batch_size\n",
    "            \n",
    "            # Apply frequency replacements\n",
    "            total_freq_replaced = 0\n",
    "            \n",
    "            for _ in range(self.num_masks):\n",
    "                # Random frequency mask width\n",
    "                f = torch.randint(1, self.max_width + 1, (1,)).item()\n",
    "                # Random starting frequency\n",
    "                f0 = torch.randint(0, h - f, (1,)).item()\n",
    "                \n",
    "                # Replace frequency band in image i with the same band from image j\n",
    "                mixed_x[i, :, f0:f0+f, :] = batch_x[j, :, f0:f0+f, :]\n",
    "                \n",
    "                # Accumulate total frequency replaced\n",
    "                total_freq_replaced += f\n",
    "            \n",
    "            # Calculate mixing ratio based on proportion of frequency replaced\n",
    "            mixing_ratio = total_freq_replaced / h\n",
    "            mixing_ratios[i] = 1 - mixing_ratio\n",
    "            \n",
    "        # Get indices for mixing labels\n",
    "        indices = torch.remainder(torch.arange(batch_size) + 1, batch_size).to(device)\n",
    "        y_a, y_b = batch_y, batch_y[indices]\n",
    "        \n",
    "        return mixed_x, y_a, y_b, mixing_ratios\n",
    "\n",
    "# Custom CNN model\n",
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(CustomCNN, self).__init__()\n",
    "        # Input size: 3x496x200\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)  # 32x248x100\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)  # 64x124x50\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)  # 128x62x25\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)  # 256x31x12\n",
    "        \n",
    "        # Calculate flattened size\n",
    "        self.flat_size = 256 * 31 * 12\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(self.flat_size, 512)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc3 = nn.Linear(128, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Convolutional layers\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.pool3(x)\n",
    "        \n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = self.pool4(x)\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(-1, self.flat_size)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Training function with augmentation\n",
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, device='cuda', \n",
    "                use_mixup=False, use_mixed_freq_mask=False):\n",
    "    \"\"\"\n",
    "    Training function with support for different augmentation techniques\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    \n",
    "    # Initialize mixup and mixed frequency masking if used\n",
    "    mixup_fn = Mixup(alpha=0.2) if use_mixup else None\n",
    "    mixed_freq_mask_fn = MixedFrequencyMasking(max_width=30, num_masks=1) if use_mixed_freq_mask else None\n",
    "    \n",
    "    best_acc = 0.0\n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        print('-' * 10)\n",
    "        \n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "                \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            \n",
    "            # Iterate over data\n",
    "            for inputs, labels, _ in tqdm(dataloaders[phase]):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # Forward pass\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Apply augmentation techniques during training\n",
    "                    if phase == 'train':\n",
    "                        if use_mixup:\n",
    "                            inputs, labels_a, labels_b, lam = mixup_fn(inputs, labels)\n",
    "                            outputs = model(inputs)\n",
    "                            loss = lam * criterion(outputs, labels_a) + (1 - lam) * criterion(outputs, labels_b)\n",
    "                        elif use_mixed_freq_mask:\n",
    "                            inputs, labels_a, labels_b, mixing_ratios = mixed_freq_mask_fn(inputs, labels)\n",
    "                            outputs = model(inputs)\n",
    "                            # Apply per-sample mixing ratios\n",
    "                            batch_loss = 0\n",
    "                            for i in range(inputs.size(0)):\n",
    "                                ratio = mixing_ratios[i]\n",
    "                                batch_loss += ratio * criterion(outputs[i:i+1], labels_a[i:i+1]) + \\\n",
    "                                             (1 - ratio) * criterion(outputs[i:i+1], labels_b[i:i+1])\n",
    "                            loss = batch_loss / inputs.size(0)\n",
    "                        else:\n",
    "                            outputs = model(inputs)\n",
    "                            loss = criterion(outputs, labels)\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    \n",
    "                    # Backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                \n",
    "                # Statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "            \n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "            \n",
    "            # Record history\n",
    "            if phase == 'train':\n",
    "                history['train_loss'].append(epoch_loss)\n",
    "                history['train_acc'].append(epoch_acc.item())\n",
    "            else:\n",
    "                history['val_loss'].append(epoch_loss)\n",
    "                history['val_acc'].append(epoch_acc.item())\n",
    "                \n",
    "                # Save best model\n",
    "                if epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "                    torch.save(model.state_dict(), 'best_model.pth')\n",
    "                    \n",
    "    print(f'Best val Acc: {best_acc:.4f}')\n",
    "    \n",
    "    # Load best model weights\n",
    "    model.load_state_dict(torch.load('best_model.pth'))\n",
    "    return model, history\n",
    "\n",
    "# Function to test the model\n",
    "def test_model(model, test_loader, criterion, device='cuda'):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    \n",
    "    # For confusion matrix\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels, _ in tqdm(test_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    test_loss = running_loss / len(test_loader.dataset)\n",
    "    test_acc = running_corrects.double() / len(test_loader.dataset)\n",
    "    \n",
    "    print(f'Test Loss: {test_loss:.4f} Acc: {test_acc:.4f}')\n",
    "    \n",
    "    return test_loss, test_acc, all_preds, all_labels\n",
    "\n",
    "# Main execution function\n",
    "def run_experiment(data_dir, batch_size=32, num_epochs=50, use_augmentation='mixed_freq_mask'):\n",
    "    \"\"\"\n",
    "    Run the complete experiment\n",
    "    Args:\n",
    "        data_dir: Root directory of the MDVR dataset\n",
    "        batch_size: Batch size for training\n",
    "        num_epochs: Number of training epochs\n",
    "        use_augmentation: Type of augmentation to use ('none', 'mixup', 'freq_mask', 'mixed_freq_mask')\n",
    "    \"\"\"\n",
    "    # Define transforms\n",
    "    # Base transform (no augmentation)\n",
    "    \n",
    "    # base_transform = transforms.Compose([\n",
    "    #     transforms.Resize((496, 200)),\n",
    "    #     transforms.ToTensor(),\n",
    "    #     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    # ])\n",
    "\n",
    "    base_transform = transforms.Compose([\n",
    "        transforms.Resize((496, 200)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5], std=[0.5])  # Single channel normalization\n",
    "    ])\n",
    "    \n",
    "    \n",
    "    # Transform with frequency masking\n",
    "    # freq_mask_transform = transforms.Compose([\n",
    "    #     transforms.Resize((496, 200)),\n",
    "    #     FrequencyMasking(max_width=30, num_masks=1),\n",
    "    #     transforms.ToTensor(),\n",
    "    #     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "    # ])\n",
    "\n",
    "    freq_mask_transform = transforms.Compose([\n",
    "        transforms.Resize((496, 200)),\n",
    "        FrequencyMasking(max_width=30, num_masks=1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5], std=[0.5])  # Single channel normalization\n",
    "    ])\n",
    "    \n",
    "    # Choose the appropriate transform based on augmentation type\n",
    "    if use_augmentation == 'freq_mask':\n",
    "        train_transform = freq_mask_transform\n",
    "    else:\n",
    "        train_transform = base_transform\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = MDVRDataset(data_dir, split='train', transform=train_transform)\n",
    "    val_dataset = MDVRDataset(data_dir, split='val', transform=base_transform)\n",
    "    test_dataset = MDVRDataset(data_dir, split='test', transform=base_transform)\n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "    \n",
    "    dataloaders = {\n",
    "        'train': train_loader,\n",
    "        'val': val_loader\n",
    "    }\n",
    "    \n",
    "    # Create model, loss function, and optimizer\n",
    "    model = CustomCNN(num_classes=2)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Device configuration\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Set augmentation flags\n",
    "    use_mixup = (use_augmentation == 'mixup')\n",
    "    use_mixed_freq_mask = (use_augmentation == 'mixed_freq_mask')\n",
    "    \n",
    "    # Train model\n",
    "    print(f\"Training with augmentation: {use_augmentation}\")\n",
    "    model, history = train_model(\n",
    "        model, dataloaders, criterion, optimizer, \n",
    "        num_epochs=num_epochs, device=device,\n",
    "        use_mixup=use_mixup, use_mixed_freq_mask=use_mixed_freq_mask\n",
    "    )\n",
    "    \n",
    "    # Test model\n",
    "    test_loss, test_acc, all_preds, all_labels = test_model(model, test_loader, criterion, device)\n",
    "    \n",
    "    # Plot training history\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history['train_loss'], label='Training')\n",
    "    plt.plot(history['val_loss'], label='Validation')\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history['train_acc'], label='Training')\n",
    "    plt.plot(history['val_acc'], label='Validation')\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_history.png')\n",
    "    \n",
    "    return model, history, (test_loss, test_acc)\n",
    "\n",
    "# Example usage\n",
    "# To run the experiment:\n",
    "model, history, test_results = run_experiment(\n",
    "    data_dir=\"C:/NPersonal/Projects/SDP/Prediction Stuff/Dataset/MDVR\",\n",
    "    batch_size=32, \n",
    "    num_epochs=50,\n",
    "    use_augmentation='mixed_freq_mask'  # or 'none', 'mixup', 'freq_mask'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ad7017-84ee-4997-8b52-006e83a28e1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c189b274-461c-4693-9358-c76095979365",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb927e4-d4e1-4df2-b5de-ca651aa8fb74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b58853-1d8b-43aa-a737-329561c7f4ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42451f80-58d5-4d11-8b34-8a66fee6f8aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b9cc86-49a2-48df-b3f5-479f6e554d4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c0c0e1-bceb-48f9-b266-6e84b80dc2ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a3e4b9-1661-4763-9737-dc92d11aac5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7193e7fa-b6b8-492b-9155-c23b8246d399",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adceeefb-ccb1-4180-aee8-42a58e9c9cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.6.0+cu126\n",
      "CUDA available: True\n",
      "CUDA version: 12.6\n",
      "CuDNN version: 90501\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "print(\"CuDNN version:\", torch.backends.cudnn.version() if torch.cuda.is_available() else \"No CUDA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0228b472-886e-43a8-91c7-a8ab480b74a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Current device: 0\n",
      "GPU name: NVIDIA GeForce GTX 1650\n",
      "Memory allocated: 0\n",
      "Memory reserved: 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Current device:\", torch.cuda.current_device())\n",
    "print(\"GPU name:\", torch.cuda.get_device_name(0))\n",
    "print(\"Memory allocated:\", torch.cuda.memory_allocated(0))\n",
    "print(\"Memory reserved:\", torch.cuda.memory_reserved(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0645b9ec-f46c-4d60-942e-2f072207e8c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/nigmu/NPersonal/Projects/SDP/nigmu-parkinsons_disease_prediction/Dataset/Italian Spectrogram Dataset/HC/AGNESE P/B1APGANRET55F170320171104'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     17\u001b[39m image_dir = \u001b[33m\"\u001b[39m\u001b[33m/home/nigmu/NPersonal/Projects/SDP/nigmu-parkinsons_disease_prediction/Dataset/Italian Spectrogram Dataset/HC/AGNESE P/B1APGANRET55F170320171104\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# List all files and pick the first image\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m image_files = [f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_dir\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m f.endswith(\u001b[33m\"\u001b[39m\u001b[33m.png\u001b[39m\u001b[33m\"\u001b[39m)]\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m image_files:\n\u001b[32m     23\u001b[39m     image_path = os.path.join(image_dir, image_files[\u001b[32m0\u001b[39m])  \u001b[38;5;66;03m# Pick first image\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/home/nigmu/NPersonal/Projects/SDP/nigmu-parkinsons_disease_prediction/Dataset/Italian Spectrogram Dataset/HC/AGNESE P/B1APGANRET55F170320171104'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def get_image_channels_pil(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    mode = image.mode\n",
    "    if mode == \"L\":\n",
    "        return 1  # Grayscale\n",
    "    elif mode == \"RGB\":\n",
    "        return 3  # RGB\n",
    "    elif mode == \"RGBA\":\n",
    "        return 4  # RGBA\n",
    "    else:\n",
    "        return f\"Unknown mode: {mode}\"\n",
    "\n",
    "# Specify the directory containing images\n",
    "image_dir = \"/home/nigmu/NPersonal/Projects/SDP/nigmu-parkinsons_disease_prediction/Dataset/Italian Spectrogram Dataset/HC/AGNESE P/B1APGANRET55F170320171104\"\n",
    "\n",
    "# List all files and pick the first image\n",
    "image_files = [f for f in os.listdir(image_dir) if f.endswith(\".png\")]\n",
    "\n",
    "if image_files:\n",
    "    image_path = os.path.join(image_dir, image_files[0])  # Pick first image\n",
    "    print(\"Checking:\", image_path)\n",
    "    print(\"Number of channels (PIL):\", get_image_channels_pil(image_path))\n",
    "else:\n",
    "    print(\"No PNG images found in the directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fe53bc-7a5d-4701-ba1e-be70b122c4f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c88719-3cab-4b2e-8128-561428c71f67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
